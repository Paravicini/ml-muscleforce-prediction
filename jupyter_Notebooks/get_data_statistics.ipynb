{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T11:47:00.519443Z",
     "start_time": "2023-12-03T11:47:00.515427Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from avi_r import AVIReader\n",
    "import glob\n",
    "import logging\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import from_numpy, unsqueeze, as_tensor\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Directory:\n",
    "    def __init__(self, trial_path):\n",
    "        self.trial_path = trial_path\n",
    "\n",
    "    @classmethod\n",
    "    def get_path(cls, root='data', label='Trials', end_folder='aligned'):\n",
    "        d = []\n",
    "        for path, subdirs, files in os.walk(f'{root}'):\n",
    "            for name in subdirs:\n",
    "                temp = os.path.join(path, name)\n",
    "                d.append(temp)\n",
    "        directory = pd.DataFrame(d, columns=[f'{label}'])\n",
    "        directory = directory[directory[f'{label}'].str.endswith(f'{end_folder}', -1*len(end_folder))]\n",
    "        #only store paths that end with {end_folder}\n",
    "        return cls(directory.iloc[:, 0])\n",
    "class Mat:\n",
    "    def __init__(self, time, emg, force):\n",
    "        # self.mat_df = pd.DataFrame({'time': time, 'emg': emg, 'force': force})\n",
    "        self.time = time\n",
    "        self.emg = emg\n",
    "        self.force = force\n",
    "\n",
    "    @classmethod\n",
    "    def load_mat_file(cls, path, struct_name='data', processed = None):\n",
    "        mat_file = sio.loadmat(path, squeeze_me=True)\n",
    "        time = mat_file[f'{struct_name}']['time'].item()\n",
    "        emg = mat_file[f'{struct_name}']['emg'].item()\n",
    "        #emg = (emg - processed['emg_mean']) / processed['emg_std']  # mean:= 0.0042, std:= 0.1927 (from dataset)\n",
    "        force = mat_file[f'{struct_name}']['force'].item()\n",
    "        return cls(time, emg, force)\n",
    "class Vid:\n",
    "\n",
    "    def __init__(self, images, fps, nr_frames):\n",
    "\n",
    "        self.images = images\n",
    "        self.fps = fps\n",
    "        self.nr_frames = nr_frames\n",
    "        self.vid_length = nr_frames / fps\n",
    "\n",
    "    @classmethod\n",
    "    def load_vid_file(cls, path, processed: dict = None):\n",
    "        video = cv.VideoCapture(f'{path}')\n",
    "        fps = video.get(cv.CAP_PROP_FPS)\n",
    "        nr_frames = video.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "        if processed is not None:\n",
    "            processed_images = []\n",
    "            while video.isOpened():\n",
    "                ret, frame = video.read()\n",
    "                if ret:\n",
    "                    processed_image = Preprocess.preprocess_frame(frame, preprocess=processed).processed_img\n",
    "                    processed_images.append(processed_image)\n",
    "                else:\n",
    "                    break\n",
    "            video.release()\n",
    "            cv.destroyAllWindows()\n",
    "            return cls(processed_images, fps, nr_frames)\n",
    "        else:\n",
    "            images = []\n",
    "            while video.isOpened():\n",
    "                ret, frame = video.read()\n",
    "                if ret:\n",
    "                    # image = frame\n",
    "                    gray_image = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "                    images.append(gray_image)\n",
    "                else:\n",
    "                    break\n",
    "            video.release()\n",
    "            cv.destroyAllWindows()\n",
    "            return cls(images, fps, nr_frames)\n",
    "\n",
    "class Preprocess:\n",
    "\n",
    "    def __init__(self, processed_img):\n",
    "        self.processed_img = processed_img\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_frame(cls, image, preprocess=None):\n",
    "        \"\"\"\n",
    "        Applies RGBtoGray, Crop and Hist_Eq on image\n",
    "        \"\"\"\n",
    "        if preprocess is None:\n",
    "            logging.info(\"preprocess is None! \")\n",
    "\n",
    "        img = RGBtoGray.to_gray(image).gray_img\n",
    "        img = Crop.crop(img).cropped_img\n",
    "        if preprocess['hist_eq']:\n",
    "            img = Hist_Eq.apply_hist_eq(img).eq_img\n",
    "        img = transforms.ToTensor()(img)\n",
    "        #img = transforms.Normalize([preprocess['img_mean']], [preprocess['img_std']])(img) ## FOR CALCULATING MEAN AND STD LEAVE THIS COMMENTED\n",
    "        img = transforms.Resize((preprocess['img_size'], preprocess['img_size']), antialias=False)(img)\n",
    "\n",
    "        return cls(img)\n",
    "\n",
    "class Crop:\n",
    "    def __init__(self, image):\n",
    "        self.cropped_img = image\n",
    "\n",
    "    @classmethod\n",
    "    def crop(cls, image):\n",
    "        cropped = image[50:540, 230:720]\n",
    "        return cls(cropped)\n",
    "\n",
    "class Hist_Eq:\n",
    "    def __init__(self, image):\n",
    "        self.eq_img = image\n",
    "\n",
    "    @classmethod\n",
    "    def apply_hist_eq(cls, image):\n",
    "        img = cv.equalizeHist(image)\n",
    "        #for adaptive Hist uncomment bellow and comment above\n",
    "        #clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        #img = clahe.apply(image)\n",
    "        return cls(img)\n",
    "\n",
    "class RGBtoGray:\n",
    "    def __init__(self, image):\n",
    "        self.gray_img = image\n",
    "\n",
    "    @classmethod\n",
    "    def to_gray(cls, image):\n",
    "        img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        return cls(img)\n",
    "\n",
    "\n",
    "\n",
    "class Trial:\n",
    "    def __init__(self, mat: Mat, vid):\n",
    "        self.mat = mat\n",
    "        self.vid = vid\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, trial_path: str, is_upper_case: bool = False, preprocessing: dict = None):\n",
    "        mat_path = Trial.get_path(trial_path, 'mat')\n",
    "        vid_path = Trial.get_path(trial_path, 'AVI')\n",
    "\n",
    "        mat_file = Mat.load_mat_file(mat_path,processed = preprocessing)\n",
    "\n",
    "        if is_upper_case:  # avi reader is case sensitive\n",
    "            vid_path = vid_path[:-3] + 'avi'\n",
    "\n",
    "        vid_file = Vid.load_vid_file(vid_path, processed=preprocessing)\n",
    "\n",
    "        return cls(mat_file, vid_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path(trial_path: str, extension: str):\n",
    "        extension_file = os.path.join(trial_path, f'*.{extension}')\n",
    "        path = glob.glob(extension_file)\n",
    "        if len(path) == 0:\n",
    "            logging.error(f'No .{extension} file found for trial:' + trial_path)\n",
    "\n",
    "        if len(path) > 1:\n",
    "            logging.warning(f'more than one .{extension} file! First was returned')\n",
    "        return path[0]\n",
    "\n",
    "class TrainUnit:\n",
    "    def __init__(self, frame, emg, force):\n",
    "        self.frame = frame.unsqueeze(0)  # might have to change to list of frames\n",
    "        self.emg = as_tensor(emg).unsqueeze(0).unsqueeze(0)\n",
    "        self.force = as_tensor(np.array([force.mean()])).unsqueeze(0)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Pytorch Dataset class, such that pytorch dataloader can be used.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.train_unit = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        frame = self.train_unit[index].frame\n",
    "        emg = self.train_unit[index].emg\n",
    "        force = self.train_unit[index].force\n",
    "        return frame, emg, force\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_unit)\n",
    "\n",
    "\n",
    "def map_emg_to_frame(trials: list, emg_fps: int = 1000):  # insert trial list\n",
    "    train_units_list = []\n",
    "    for trial in trials:\n",
    "        us_fps = trial.vid.fps\n",
    "        vid_length = trial.vid.vid_length\n",
    "        emg_length = trial.mat.time[-1]\n",
    "        time_diff = vid_length - emg_length\n",
    "        if time_diff < 0:\n",
    "            logging.error(\"Video length is shorter than EMG length\")\n",
    "        surplus_frames = int(time_diff * us_fps) + 1\n",
    "        frames = trial.vid.images[0: int(trial.vid.nr_frames - surplus_frames)]\n",
    "        # map emg to frames\n",
    "        fps_ratio = emg_fps / us_fps  # fps = frames per second\n",
    "        for i in range(0, len(frames)):\n",
    "            emg = trial.mat.emg[int(i * fps_ratio):int((i + 1) * fps_ratio)][:int(fps_ratio)]\n",
    "            force = trial.mat.force[int(i * fps_ratio):int((i + 1) * fps_ratio)][:int(fps_ratio)]\n",
    "            train_unit = TrainUnit(frames[i], emg, force)\n",
    "            train_units_list.append(train_unit)\n",
    "    return train_units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING\n",
    "\n",
    "IMG_SIZE = 224\n",
    "HIST_EQ = False\n",
    "IMG_MEAN = 0 #0.1756  # Determined experimentally default 0.1756432205438614\n",
    "IMG_STD =  1 #0.1135  # Determined experimentally default 0.11345013976097107\n",
    "\n",
    "# EMG PREPROCESSING\n",
    "EMG_MEAN = -0.0211  # Determined experimentally default -0.021118670256266833\n",
    "EMG_STD = 0.6729\n",
    "############################################################################################################\n",
    "#           SET PARAMETERS FOR TRAINING           #\n",
    "############################################################################################################\n",
    "\n",
    "MODE = 'autoencoder'  # choose from end2end/ autoencoder/ force_prediction\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "CRITERION = 'MSE'  # choose from MSE/ L1/ HUBER\n",
    "OPTIMIZER = 'Adam'  # choose from Adam/ SGD\n",
    "LEARNING_RATE = 0.001  # default = 0.001\n",
    "MOMENTUM = 0.9  # default = 0.9\n",
    "\n",
    "CHECKPOINT_PATH = 'models/checkpoints/'\n",
    "\n",
    "############################################################################################################\n",
    "#          GENERATE DICTIONARIES          #\n",
    "############################################################################################################\n",
    "\n",
    "PREPROCESSING = {\n",
    "    'img_size': IMG_SIZE,\n",
    "    'hist_eq': HIST_EQ,\n",
    "    'img_mean': IMG_MEAN,\n",
    "    'img_std': IMG_STD,\n",
    "    'emg_mean': EMG_MEAN,\n",
    "    'emg_std': EMG_STD\n",
    "}\n",
    "\n",
    "PARAMS = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'criterion': CRITERION,\n",
    "    'optimizer': OPTIMIZER,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'momentum': MOMENTUM\n",
    "}\n",
    "\n",
    "CHECKPOINT = {\n",
    "    'path': CHECKPOINT_PATH,\n",
    "    'prefix': 'ckpt',\n",
    "    'counter': 0,\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T16:14:14.271621Z",
     "start_time": "2023-12-03T16:14:14.266909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_paths: 15\n"
     ]
    }
   ],
   "source": [
    "trial_paths = Directory.get_path().trial_path\n",
    "print(f'trial_paths: {len(trial_paths)}')\n",
    "trials = []\n",
    "for path in trial_paths:\n",
    "    trial = Trial.from_files(path, is_upper_case=True,preprocessing=PREPROCESSING)\n",
    "    trials.append(trial)\n",
    "\n",
    "trial_units = map_emg_to_frame(trials)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T16:14:26.925277Z",
     "start_time": "2023-12-03T16:14:17.391196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMG mean: 0.00013043224161738508\n",
      "EMG std: 0.1296671366367021\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def for_emg(dataset):\n",
    "    \"\"\"Compute the mean and std value of dataset.\"\"\"\n",
    "    # Calculate mean and std of the frames in the dataset\n",
    "    # Calculate mean and std of the frames in the dataset\n",
    "    emg_mean = 0\n",
    "    for unit in dataset:\n",
    "        emg_mean += unit.emg.squeeze(1).mean(1).sum(0)\n",
    "    emg_mean = emg_mean / len(dataset)\n",
    "\n",
    "    emg_var = 0.0\n",
    "    sample_count = 0\n",
    "    for unit in dataset:\n",
    "        batch_samples = unit.frame.size(0)\n",
    "        # emg = batch.frames.view(batch_samples, 1, -1)\n",
    "        sample_count += unit.emg.nelement()\n",
    "        emg_var += ((unit.emg.squeeze() - emg_mean) ** 2).sum(0)\n",
    "    emg_std = torch.sqrt(emg_var / sample_count)\n",
    "\n",
    "    return emg_mean, emg_std\n",
    "emg_mean, emg_std = for_emg(trial_units)\n",
    "print(f'EMG mean: {emg_mean}')\n",
    "print(f'EMG std: {emg_std}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T16:13:39.853803Z",
     "start_time": "2023-12-03T16:13:39.817504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMG mean: -0.021118670256266833\n",
      "EMG std: 0.6728964018510745\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames mean: 0.1756432205438614\n",
      "Frames std: 0.11345013976097107\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def for_frames(dataset):\n",
    "    \"\"\"Compute the mean and std value of dataset.\"\"\"\n",
    "    # Calculate mean and std of the frames in the dataset\n",
    "    # Calculate mean and std of the frames in the dataset\n",
    "    frames_mean = 0\n",
    "    for unit in dataset:\n",
    "        frames = unit.frame.view( 1, -1)\n",
    "        frames_mean += frames.mean(1).sum(0)\n",
    "    frames_mean = frames_mean / len(dataset)\n",
    "\n",
    "    frames_var = 0.0\n",
    "    pixel_count = 0\n",
    "    for unit in dataset:\n",
    "        frames = unit.frame.view( 1, -1)\n",
    "        frames_var += ((frames.squeeze(0) - frames_mean) ** 2).sum(0)\n",
    "        pixel_count += frames.nelement()\n",
    "    frames_std = torch.sqrt(frames_var / pixel_count)\n",
    "\n",
    "    return frames_mean, frames_std\n",
    "\n",
    "frames_mean, frames_std = for_frames(trial_units)\n",
    "print(f'Frames mean: {frames_mean}')\n",
    "print(f'Frames std: {frames_std}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T16:14:49.637324Z",
     "start_time": "2023-12-03T16:14:49.454169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames mean: 0.1756432205438614\n",
      "Frames std: 0.11345013976097107\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
